{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Principal Packages\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "## Complements\n",
    "import pandas as pd\n",
    "import xlsxwriter\n",
    "import os \n",
    "from cmath import nan\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "''' Main function, it will execute all of the functions created'''\n",
    "\n",
    "    email = get_email()\n",
    "    password = get_password()\n",
    "    job = get_job()\n",
    "    location = get_location()\n",
    "\n",
    "    ## Execute body of the function\n",
    "    logging_linkedin()\n",
    "    webscrap_ds_linkedin_jobs()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_email():\n",
    "    email= input('Please insert the email of your linkeidin Account')\n",
    "    return email\n",
    "\n",
    "def get_password():\n",
    "    password= input('Please insert password of your linkedin Account')\n",
    "    return password\n",
    "\n",
    "def get_job():\n",
    "    job= input('Insert job name')\n",
    "    return job\n",
    "\n",
    "def get_location():\n",
    "    location= input('Insert location')\n",
    "    return location\n",
    "def logging_linkedin(email,password,job,location):\n",
    "\n",
    "'''  This function  use a bot to log in into your linkeidn account, its important that you install chromedriver \n",
    "     to use this function properly    '''\n",
    "\n",
    "    ## Set up chrome driver \n",
    "     global wd\n",
    "     wd=webdriver.Chrome(executable_path=os.popen('which chromedriver').read().strip())\n",
    "     wd.get(f'https://www.linkedin.com/login')\n",
    "\n",
    "\n",
    "    #login\n",
    "     time.sleep(3)\n",
    "     wd.find_element(By.ID,'username').send_keys(email)\n",
    "     wd.find_element(By.ID,'password').send_keys(password)\n",
    "     wd.find_element(By.ID,'password').send_keys(Keys.RETURN)\n",
    "\n",
    "     \n",
    "     job = search_job.replace(' ', '%20')\n",
    "     location = search_location.replace(' ', '%20')\n",
    "\n",
    " \n",
    "     \n",
    "     linkedin_job_url = f'https://www.linkedin.com/jobs/search/?currentJobId=3254159027&geoId=101739942&keywords={job}&location={location}'\n",
    "     wd.get(linkedin_job_url)\n",
    "\n",
    " def webscrap_ds_linkedin_jobs(save_file=f'linkedin_ws_{job}.xlsx'):\n",
    "\n",
    "'''   Web scrapping every single job based on the job name and location, would extract all the raw data and save it in the computer as an\n",
    "      excel file                           '''\n",
    "\n",
    "\n",
    "     name=[]\n",
    "     company=[]\n",
    "     location=[]\n",
    "     type=[]\n",
    "     contract=[]\n",
    "     industry=[]\n",
    "     description=[]\n",
    "\n",
    "    for page in range(1,41):\n",
    "        wd.find_element(By.XPATH, f\"//button[@aria-label='Page {page}']\").click()\n",
    "        job_list=wd.find_elements(By.CLASS_NAME,'occludable-update')\n",
    "        job_list=job_list[:-1]\n",
    "    \n",
    "    \n",
    "\n",
    "        for job in job_list:\n",
    "            wd.execute_script(\"arguments[0].scrollIntoView();\",job)\n",
    "            job.click()\n",
    "            time.sleep(3)\n",
    "            [position,comp,loc,tp]=job.text.split('\\n')[:4]\n",
    "      \n",
    "            descr=wd.find_element(By.CLASS_NAME,'jobs-unified-description__content').text\n",
    "       \n",
    "            try:\n",
    "               cont= wd.find_elements(By.CLASS_NAME,'jobs-unified-top-card__job-insight')[0].text\n",
    "            except:\n",
    "               cont= nan\n",
    "           \n",
    "            try:\n",
    "               inds=wd.find_elements(By.CLASS_NAME,'jobs-unified-top-card__job-insight')[1].text\n",
    "            except:\n",
    "               inds=nan\n",
    "          \n",
    "        name.append(position)\n",
    "        company.append(comp)\n",
    "        location.append(loc)\n",
    "        type.append(tp)\n",
    "        contract.append(cont)\n",
    "        industry.append(inds)\n",
    "        description.append(descr)\n",
    "\n",
    "    df=pd.DataFrame(columns=['Name','Company','Location','Type','Contract','Industry','Description'])\n",
    "    df['Name'] = name\n",
    "    df['Company'] = company\n",
    "    df['Location'] = location\n",
    "    df['Type']= type\n",
    "    df['Contract'] = contract\n",
    "    df['Industry'] = industry\n",
    "    df['Description'] = description\n",
    "\n",
    "\n",
    "\n",
    "       \n",
    "    # save the df\n",
    "    df.to_excel(save_file, engine='xlsxwriter')\n",
    "\n",
    "\n",
    "if __name__=='__main__':\n",
    "    main()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
